"""
PDF æ–‡æª”è™•ç†å’Œå‘é‡åŒ–è…³æœ¬
"""

import os
import asyncio
from typing import List, Dict, Any
from pathlib import Path
import hashlib
from datetime import datetime

try:
    import PyPDF2
    HAS_PYPDF2 = True
except ImportError:
    HAS_PYPDF2 = False

try:
    import fitz  # PyMuPDF
    HAS_PYMUPDF = True
except ImportError:
    HAS_PYMUPDF = False

from app.core.vector_db import vector_db
from app.core.logger import logger


class PDFProcessor:
    """PDF æ–‡æª”è™•ç†å™¨"""
    
    def __init__(self):
        self.pdf_folder = Path("./documents")
        self.processed_folder = Path("./documents/processed")
        self.chunk_size = 1000  # æ¯å€‹æ–‡æª”å¡Šçš„å­—ç¬¦æ•¸
        self.chunk_overlap = 200  # é‡ç–Šå­—ç¬¦æ•¸
        
        # å‰µå»ºè³‡æ–™å¤¾
        self.pdf_folder.mkdir(exist_ok=True)
        self.processed_folder.mkdir(exist_ok=True)
    
    async def process_all_pdfs(self) -> bool:
        """è™•ç†æ‰€æœ‰ PDF æ–‡æª”"""
        try:
            pdf_files = list(self.pdf_folder.glob("*.pdf"))
            
            if not pdf_files:
                logger.info("æœªæ‰¾åˆ° PDF æ–‡æª”")
                return True
            
            logger.info(f"æ‰¾åˆ° {len(pdf_files)} å€‹ PDF æ–‡æª”")
            
            all_documents = []
            
            for pdf_file in pdf_files:
                # æª¢æŸ¥æ˜¯å¦å·²è™•ç†
                if self._is_processed(pdf_file):
                    logger.info(f"è·³éå·²è™•ç†çš„æ–‡æª”: {pdf_file.name}")
                    continue
                
                logger.info(f"æ­£åœ¨è™•ç†: {pdf_file.name}")
                
                # æå–æ–‡å­—
                text = await self._extract_text_from_pdf(pdf_file)
                if not text:
                    logger.warning(f"ç„¡æ³•æå–æ–‡å­—: {pdf_file.name}")
                    continue
                
                # åˆ†å¡Šè™•ç†
                chunks = self._split_text_into_chunks(text)
                
                # è½‰æ›ç‚ºæ–‡æª”æ ¼å¼
                documents = self._create_documents(chunks, pdf_file)
                all_documents.extend(documents)
                
                # æ¨™è¨˜ç‚ºå·²è™•ç†
                self._mark_as_processed(pdf_file)
                
                logger.info(f"å®Œæˆè™•ç†: {pdf_file.name} -> {len(documents)} å€‹æ–‡æª”å¡Š")
            
            # æ‰¹é‡æ–°å¢åˆ°å‘é‡è³‡æ–™åº«
            if all_documents:
                success = await vector_db.add_documents(all_documents)
                if success:
                    logger.info(f"æˆåŠŸæ–°å¢ {len(all_documents)} å€‹æ–‡æª”åˆ°å‘é‡è³‡æ–™åº«")
                else:
                    logger.error("æ–°å¢æ–‡æª”åˆ°å‘é‡è³‡æ–™åº«å¤±æ•—")
                    return False
            
            return True
            
        except Exception as e:
            logger.error(f"è™•ç† PDF å¤±æ•—: {e}")
            return False
    
    async def _extract_text_from_pdf(self, pdf_path: Path) -> str:
        """å¾ PDF æå–æ–‡å­—"""
        try:
            text = ""
            
            # å„ªå…ˆä½¿ç”¨ PyMuPDF (æ›´å¥½çš„æ–‡å­—æå–)
            if HAS_PYMUPDF:
                text = await self._extract_with_pymupdf(pdf_path)
            elif HAS_PYPDF2:
                text = await self._extract_with_pypdf2(pdf_path)
            else:
                logger.error("æ²’æœ‰å®‰è£ PDF è™•ç†åº« (PyMuPDF æˆ– PyPDF2)")
                return ""
            
            # æ¸…ç†æ–‡å­—
            text = self._clean_text(text)
            
            return text
            
        except Exception as e:
            logger.error(f"æå– PDF æ–‡å­—å¤±æ•—: {e}")
            return ""
    
    async def _extract_with_pymupdf(self, pdf_path: Path) -> str:
        """ä½¿ç”¨ PyMuPDF æå–æ–‡å­—"""
        try:
            doc = fitz.open(str(pdf_path))
            text = ""
            
            for page_num in range(len(doc)):
                page = doc.load_page(page_num)
                text += page.get_text()
            
            doc.close()
            return text
            
        except Exception as e:
            logger.error(f"PyMuPDF æå–å¤±æ•—: {e}")
            return ""
    
    async def _extract_with_pypdf2(self, pdf_path: Path) -> str:
        """ä½¿ç”¨ PyPDF2 æå–æ–‡å­—"""
        try:
            text = ""
            
            with open(pdf_path, 'rb') as file:
                pdf_reader = PyPDF2.PdfReader(file)
                
                for page_num in range(len(pdf_reader.pages)):
                    page = pdf_reader.pages[page_num]
                    text += page.extract_text()
            
            return text
            
        except Exception as e:
            logger.error(f"PyPDF2 æå–å¤±æ•—: {e}")
            return ""
    
    def _clean_text(self, text: str) -> str:
        """æ¸…ç†æ–‡å­—"""
        # ç§»é™¤å¤šé¤˜çš„ç©ºç™½å­—ç¬¦
        text = ' '.join(text.split())
        
        # ç§»é™¤ç‰¹æ®Šå­—ç¬¦
        text = text.replace('\x00', '')
        
        return text.strip()
    
    def _split_text_into_chunks(self, text: str) -> List[str]:
        """å°‡æ–‡å­—åˆ†å¡Š"""
        if len(text) <= self.chunk_size:
            return [text]
        
        chunks = []
        start = 0
        
        while start < len(text):
            end = start + self.chunk_size
            
            # å¦‚æœä¸æ˜¯æœ€å¾Œä¸€å¡Šï¼Œå°‹æ‰¾åˆé©çš„åˆ†å‰²é»
            if end < len(text):
                # å°‹æ‰¾æœ€è¿‘çš„å¥è™Ÿæˆ–æ›è¡Œ
                for i in range(end, start, -1):
                    if text[i] in '.ã€‚\n':
                        end = i + 1
                        break
            
            chunk = text[start:end]
            chunks.append(chunk)
            
            # ä¸‹ä¸€å¡Šçš„é–‹å§‹ä½ç½® (è€ƒæ…®é‡ç–Š)
            start = end - self.chunk_overlap
            
        return chunks
    
    def _create_documents(self, chunks: List[str], pdf_file: Path) -> List[Dict[str, Any]]:
        """å‰µå»ºæ–‡æª”å°è±¡"""
        documents = []
        
        for i, chunk in enumerate(chunks):
            document = {
                "id": f"{pdf_file.stem}_{i}",
                "content": chunk,
                "source": pdf_file.name,
                "title": pdf_file.stem,
                "category": self._determine_category(pdf_file.name),
                "created_at": datetime.now().isoformat(),
                "chunk_index": i,
                "total_chunks": len(chunks)
            }
            documents.append(document)
        
        return documents
    
    def _determine_category(self, filename: str) -> str:
        """æ ¹æ“šæª”æ¡ˆåç¨±ç¢ºå®šé¡åˆ¥"""
        filename_lower = filename.lower()
        
        if any(keyword in filename_lower for keyword in ['product', 'ç”¢å“', 'feature', 'åŠŸèƒ½']):
            return "product"
        elif any(keyword in filename_lower for keyword in ['price', 'åƒ¹æ ¼', 'pricing', 'å®šåƒ¹']):
            return "pricing"
        elif any(keyword in filename_lower for keyword in ['manual', 'æ‰‹å†Š', 'guide', 'æŒ‡å—']):
            return "manual"
        elif any(keyword in filename_lower for keyword in ['faq', 'å¸¸è¦‹å•é¡Œ', 'qa']):
            return "faq"
        else:
            return "general"
    
    def _get_file_hash(self, pdf_file: Path) -> str:
        """ç²å–æ–‡æª”çš„ hash å€¼"""
        with open(pdf_file, 'rb') as f:
            return hashlib.md5(f.read()).hexdigest()
    
    def _is_processed(self, pdf_file: Path) -> bool:
        """æª¢æŸ¥æ–‡æª”æ˜¯å¦å·²è™•ç†"""
        hash_file = self.processed_folder / f"{pdf_file.stem}.hash"
        
        if not hash_file.exists():
            return False
        
        # æ¯”è¼ƒ hash å€¼
        current_hash = self._get_file_hash(pdf_file)
        with open(hash_file, 'r') as f:
            stored_hash = f.read().strip()
        
        return current_hash == stored_hash
    
    def _mark_as_processed(self, pdf_file: Path):
        """æ¨™è¨˜æ–‡æª”ç‚ºå·²è™•ç†"""
        hash_file = self.processed_folder / f"{pdf_file.stem}.hash"
        current_hash = self._get_file_hash(pdf_file)
        
        with open(hash_file, 'w') as f:
            f.write(current_hash)
    
    async def reprocess_all(self) -> bool:
        """é‡æ–°è™•ç†æ‰€æœ‰æ–‡æª”"""
        logger.info("æ¸…ç†è™•ç†è¨˜éŒ„...")
        
        # æ¸…ç©ºè™•ç†è¨˜éŒ„
        for hash_file in self.processed_folder.glob("*.hash"):
            hash_file.unlink()
        
        # é‡æ–°è™•ç†
        return await self.process_all_pdfs()


# å‰µå»ºå…¨åŸŸå¯¦ä¾‹
pdf_processor = PDFProcessor()


async def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸ“š PDF æ–‡æª”è™•ç†å™¨")
    print("=" * 50)
    
    # é¡¯ç¤ºèªªæ˜
    print(f"ğŸ“ PDF æ–‡æª”è³‡æ–™å¤¾: {pdf_processor.pdf_folder}")
    print(f"ğŸ“Š è™•ç†è¨˜éŒ„è³‡æ–™å¤¾: {pdf_processor.processed_folder}")
    print(f"ğŸ“ æ–‡æª”å¡Šå¤§å°: {pdf_processor.chunk_size} å­—ç¬¦")
    print(f"ğŸ”„ é‡ç–Šå¤§å°: {pdf_processor.chunk_overlap} å­—ç¬¦")
    print()
    
    # æª¢æŸ¥ä¾è³´
    if not HAS_PYMUPDF and not HAS_PYPDF2:
        print("âŒ éŒ¯èª¤ï¼šæ²’æœ‰å®‰è£ PDF è™•ç†åº«")
        print("è«‹å®‰è£ï¼špip install PyMuPDF æˆ– pip install PyPDF2")
        return
    
    pdf_lib = "PyMuPDF" if HAS_PYMUPDF else "PyPDF2"
    print(f"ğŸ“– ä½¿ç”¨ PDF åº«: {pdf_lib}")
    print()
    
    # è™•ç†æ–‡æª”
    success = await pdf_processor.process_all_pdfs()
    
    if success:
        print("âœ… PDF è™•ç†å®Œæˆ")
    else:
        print("âŒ PDF è™•ç†å¤±æ•—")


if __name__ == "__main__":
    asyncio.run(main())
