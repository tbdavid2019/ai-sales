import streamlit as st
import asyncio
import cv2
import numpy as np
import base64
import json
import io
from PIL import Image
import threading
import time
from datetime import datetime
import sys
import os
import logging
from typing import Dict, Any, Optional, List, Tuple
from pathlib import Path
import contextlib
import gc

# æ·»åŠ å°ˆæ¡ˆè·¯å¾‘
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# è¨­å®šæ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œç¢ºä¿è³‡æºæ­£ç¢ºæ¸…ç†
@contextlib.asynccontextmanager
async def safe_async_context():
    """ç¢ºä¿ç•°æ­¥æ“ä½œçš„è³‡æºæ­£ç¢ºæ¸…ç†"""
    try:
        yield
    finally:
        # æ›´ç©æ¥µçš„è³‡æºæ¸…ç†
        try:
            # ç­‰å¾…æ‰€æœ‰æ›èµ·çš„ gRPC èª¿ç”¨å®Œæˆ
            await asyncio.sleep(0.2)
            
            # å¼·åˆ¶é€²è¡Œåƒåœ¾å›æ”¶ï¼Œæ¸…ç†æœªå®Œæˆçš„ gRPC èª¿ç”¨
            gc.collect()
            
            # å†æ¬¡ç­‰å¾…ï¼Œç¢ºä¿æ¸…ç†å®Œæˆ
            await asyncio.sleep(0.1)
        except Exception as cleanup_error:
            logger.warning(f"è³‡æºæ¸…ç†éç¨‹ä¸­å‡ºç¾è­¦å‘Š: {cleanup_error}")
            # ä¸é‡æ–°æ‹‹å‡ºç•°å¸¸ï¼Œå› ç‚ºé€™åªæ˜¯æ¸…ç†éç¨‹çš„è­¦å‘Š

# å®‰å…¨çš„ç•°æ­¥é‹è¡Œå‡½æ•¸
def safe_run_async(coro):
    """å®‰å…¨åœ°é‹è¡Œç•°æ­¥å‡½æ•¸ï¼Œé¿å… event loop è¡çª"""
    try:
        # å˜—è©¦ç²å–ç¾æœ‰çš„ event loop
        loop = asyncio.get_running_loop()
        if loop.is_running():
            # å¦‚æœ loop æ­£åœ¨é‹è¡Œï¼Œå‰µå»ºä¸€å€‹æ–°çš„ç·šç¨‹ä¾†é‹è¡Œå”ç¨‹
            import concurrent.futures
            import threading
            
            def run_coro():
                # åœ¨æ–°ç·šç¨‹ä¸­å‰µå»ºæ–°çš„ event loop
                new_loop = asyncio.new_event_loop()
                asyncio.set_event_loop(new_loop)
                try:
                    # åŒ…è£å”ç¨‹ä»¥ç¢ºä¿è³‡æºæ¸…ç†
                    async def wrapped_coro():
                        async with safe_async_context():
                            return await coro
                    return new_loop.run_until_complete(wrapped_coro())
                finally:
                    new_loop.close()
            
            with concurrent.futures.ThreadPoolExecutor() as executor:
                future = executor.submit(run_coro)
                return future.result(timeout=60)  # è¨­ç½®è¶…æ™‚
        else:
            return asyncio.run(coro)
    except RuntimeError as e:
        if "cannot be called from a running event loop" in str(e):
            # å¦‚æœæ˜¯ event loop è¡çªï¼Œä½¿ç”¨ç·šç¨‹æ± åŸ·è¡Œ
            import concurrent.futures
            import threading
            
            def run_coro():
                new_loop = asyncio.new_event_loop()
                asyncio.set_event_loop(new_loop)
                try:
                    async def wrapped_coro():
                        async with safe_async_context():
                            return await coro
                    return new_loop.run_until_complete(wrapped_coro())
                finally:
                    new_loop.close()
            
            with concurrent.futures.ThreadPoolExecutor() as executor:
                future = executor.submit(run_coro)
                return future.result(timeout=60)
        else:
            # å…¶ä»– RuntimeErrorï¼Œç›´æ¥é‹è¡Œ
            return asyncio.run(coro)
    except Exception as e:
        logger.error(f"safe_run_async åŸ·è¡Œå¤±æ•—: {e}")
        raise

# å°å…¥æ ¸å¿ƒæ¨¡çµ„
try:
    from app.core.workflow import workflow_manager
    from app.core.ui_handler import process_user_request  # ä½¿ç”¨çµ±ä¸€è™•ç†å‡½æ•¸
    from app.agents.vision_agent import VisionAgent
    from app.models.llm_factory import LLMFactory
    from app.config import settings
    logger.info("æ‰€æœ‰æ¨¡çµ„è¼‰å…¥æˆåŠŸ")
except ImportError as e:
    logger.error(f"æ¨¡çµ„è¼‰å…¥å¤±æ•—: {e}")
    st.error(f"ç³»çµ±è¼‰å…¥å¤±æ•—: {e}")
    st.stop()

# è¨­å®šé é¢é…ç½®
st.set_page_config(
    page_title="AI Sales æ™ºèƒ½éŠ·å”®åŠ©æ‰‹",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªè¨‚ CSS
st.markdown("""
<style>
    .main-header {
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        padding: 1rem;
        border-radius: 10px;
        color: white;
        text-align: center;
        margin-bottom: 2rem;
    }
    .chat-container {
        max-height: 500px;
        overflow-y: auto;
        padding: 1rem;
        background-color: #f8f9fa;
        border-radius: 10px;
        margin-bottom: 1rem;
    }
    .user-message {
        background-color: #e3f2fd;
        padding: 0.5rem 1rem;
        margin: 0.5rem 0;
        border-radius: 15px;
        text-align: right;
    }
    .assistant-message {
        background-color: #f5f5f5;
        padding: 0.5rem 1rem;
        margin: 0.5rem 0;
        border-radius: 15px;
        text-align: left;
    }
    .emotion-display {
        background: linear-gradient(45deg, #ff6b6b, #4ecdc4);
        padding: 1rem;
        border-radius: 10px;
        color: white;
        text-align: center;
        margin: 1rem 0;
    }
    .camera-container {
        border: 2px solid #ddd;
        border-radius: 10px;
        padding: 1rem;
        text-align: center;
    }
</style>
""", unsafe_allow_html=True)

# åˆå§‹åŒ– session state
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []
    # AI ä¸»å‹•æ‰“æ‹›å‘¼
    greeting_message = "æ‚¨å¥½ï¼æˆ‘æ˜¯ AI éŠ·å”®åŠ©ç†ï¼Œå¾ˆé«˜èˆˆç‚ºæ‚¨æœå‹™ã€‚æ‚¨å¯ä»¥è©¢å•ç”¢å“ã€å®‰æ’æœƒè­°ï¼Œæˆ–ä¸Šå‚³åç‰‡è®“æˆ‘æ›´èªè­˜æ‚¨ï¼"
    st.session_state.chat_history.append(("", greeting_message))
    
if 'user_profile' not in st.session_state:
    st.session_state.user_profile = {}
if 'vision_agent' not in st.session_state:
    st.session_state.vision_agent = VisionAgent()
if 'current_emotion' not in st.session_state:
    st.session_state.current_emotion = None
if 'camera_active' not in st.session_state:
    st.session_state.camera_active = False
if 'current_camera_image' not in st.session_state:
    st.session_state.current_camera_image = None
if 'emotion_history' not in st.session_state:
    st.session_state.emotion_history = []

# ä¸»æ¨™é¡Œ
st.markdown("""
<div class="main-header">
    <h1>ğŸ¤– AI Sales æ™ºèƒ½éŠ·å”®åŠ©æ‰‹</h1>
    <p>æ”¯æ´å³æ™‚æ”å½±æ©Ÿæƒ…ç·’åˆ†æçš„å¤šä»£ç†äººéŠ·å”®ç³»çµ±</p>
</div>
""", unsafe_allow_html=True)

# å´é‚Šæ¬„
with st.sidebar:
    st.header("ğŸ”§ ç³»çµ±è¨­å®š")
    
    # äº’å‹•æ¨¡å¼é¸æ“‡
    interaction_mode = st.selectbox(
        "äº’å‹•æ¨¡å¼",
        ["sales", "support", "consultation"],
        index=0,
        help="é¸æ“‡ AI åŠ©ç†çš„äº’å‹•é¢¨æ ¼"
    )
    
    # è™›æ“¬äººèˆ‡æ–‡å­— UI æ¨¡å¼é¸æ“‡
    st.subheader("ğŸ¤– å›æ‡‰æ¨¡å¼")
    response_mode = st.selectbox(
        "å›æ‡‰æ¨¡å¼",
        ["ä¸€èˆ¬æ–‡å­—æ¨¡å¼ (Chat)", "è™›æ“¬äººæ¨¡å¼ (Virtual Human)"],
        index=0,
        help="é¸æ“‡ AI çš„å›æ‡‰é¢¨æ ¼ï¼šä¸€èˆ¬æ¨¡å¼æä¾›è©³ç´°å›ç­”ï¼Œè™›æ“¬äººæ¨¡å¼æä¾›ç°¡çŸ­äº’å‹•"
    )
    
    # LLM è¼¸å‡ºåƒæ•¸æ§åˆ¶
    st.subheader("ğŸ“ è¼¸å‡ºåƒæ•¸")
    if "è™›æ“¬äºº" in response_mode:
        max_tokens = st.slider("å›æ‡‰é•·åº¦ (å­—æ•¸)", 20, 200, 50, 10, help="è™›æ“¬äººæ¨¡å¼å»ºè­°ä½¿ç”¨è¼ƒçŸ­çš„å›æ‡‰")
        temperature = st.slider("å›æ‡‰å‰µæ„åº¦", 0.1, 1.0, 0.8, 0.1, help="è™›æ“¬äººæ¨¡å¼å»ºè­°ä½¿ç”¨è¼ƒé«˜çš„å‰µæ„åº¦")
    else:
        max_tokens = st.slider("å›æ‡‰é•·åº¦ (å­—æ•¸)", 100, 2000, 500, 50, help="ä¸€èˆ¬æ¨¡å¼å¯ä»¥ä½¿ç”¨è¼ƒé•·çš„å›æ‡‰")
        temperature = st.slider("å›æ‡‰å‰µæ„åº¦", 0.1, 1.0, 0.7, 0.1, help="ä¸€èˆ¬æ¨¡å¼å»ºè­°ä½¿ç”¨ä¸­ç­‰å‰µæ„åº¦")
    
    # è¦–è¦ºåˆ†æè¨­å®š
    st.subheader("ğŸ‘ï¸ è¦–è¦ºåˆ†æ")
    vision_enabled = st.checkbox("å•Ÿç”¨æƒ…ç·’åˆ†æ", value=True)
    emotion_sensitivity = st.slider("æƒ…ç·’æ•æ„Ÿåº¦", 0.1, 1.0, 0.7, 0.1)
    
    # ç³»çµ±ç‹€æ…‹
    st.subheader("ğŸ“Š ç³»çµ±ç‹€æ…‹")
    st.success("âœ… æ ¸å¿ƒç³»çµ±å·²è¼‰å…¥")
    if st.session_state.camera_active:
        st.success("âœ… æ”å½±æ©Ÿå·²å•Ÿå‹•")
        # é¡¯ç¤ºæ”å½±æ©Ÿåœ–ç‰‡ç‹€æ…‹
        if 'current_camera_image' in st.session_state and st.session_state.current_camera_image:
            st.info(f"ğŸ“¸ æ”å½±æ©Ÿåœ–ç‰‡å·²ä¿å­˜ ({len(st.session_state.current_camera_image)} å­—å…ƒ)")
        else:
            st.warning("ğŸ“¸ å°šæœªæ‹ç…§")
    else:
        st.info("ğŸ“· æ”å½±æ©Ÿå¾…æ©Ÿä¸­")
    
    # ç•¶å‰è¨­å®šé¡¯ç¤º
    st.subheader("âš™ï¸ ç•¶å‰è¨­å®š")
    st.write(f"**äº’å‹•æ¨¡å¼**: {interaction_mode}")
    st.write(f"**å›æ‡‰æ¨¡å¼**: {response_mode}")
    st.write(f"**æœ€å¤§å›æ‡‰é•·åº¦**: {max_tokens} å­—")
    st.write(f"**å‰µæ„åº¦**: {temperature}")
    if vision_enabled:
        st.write(f"**æƒ…ç·’æ•æ„Ÿåº¦**: {emotion_sensitivity}")
    else:
        st.write("**æƒ…ç·’åˆ†æ**: å·²åœç”¨")
    
    # ç”¨æˆ¶æª”æ¡ˆ
    st.subheader("ğŸ‘¤ ç”¨æˆ¶æª”æ¡ˆ")
    if st.session_state.user_profile:
        for key, value in st.session_state.user_profile.items():
            st.write(f"**{key}**: {value}")
    else:
        st.write("å°šæœªå»ºç«‹ç”¨æˆ¶æª”æ¡ˆ")

# ä¸»è¦å…§å®¹å€åŸŸ
col1, col2 = st.columns([2, 1])

with col1:
    st.header("ğŸ’¬ å°è©±å€åŸŸ")
    
    # èŠå¤©æ­·å²é¡¯ç¤º
    chat_container = st.container()
    with chat_container:
        for i, (user_msg, assistant_msg) in enumerate(st.session_state.chat_history):
            if user_msg:
                st.markdown(f'<div class="user-message">ğŸ‘¤ {user_msg}</div>', unsafe_allow_html=True)
            if assistant_msg:
                st.markdown(f'<div class="assistant-message">ğŸ¤– {assistant_msg}</div>', unsafe_allow_html=True)
    
    # è¼¸å…¥å€åŸŸ
    st.subheader("âœï¸ è¼¸å…¥è¨Šæ¯")
    
    # ä½¿ç”¨è¡¨å–®ä¾†è™•ç†è¼¸å…¥
    with st.form("chat_form", clear_on_submit=True):
        user_input = st.text_input("è«‹è¼¸å…¥æ‚¨çš„å•é¡Œ...", key="user_message")
        submitted = st.form_submit_button("ğŸ’¬ ç™¼é€è¨Šæ¯", type="primary")
        
        if submitted and user_input:
            # è™•ç†ç”¨æˆ¶è¨Šæ¯
            with st.spinner("AI æ­£åœ¨æ€è€ƒ..."):
                try:
                    # æª¢æŸ¥æ˜¯å¦æœ‰æ”å½±æ©Ÿåœ–ç‰‡
                    camera_image = None
                    if st.session_state.camera_active and 'current_camera_image' in st.session_state:
                        camera_image = st.session_state.current_camera_image
                        logger.info(f"ä½¿ç”¨æ”å½±æ©Ÿåœ–ç‰‡ï¼Œé•·åº¦: {len(camera_image) if camera_image else 0}")
                    
                    # æ·»åŠ æ›´å¤šdebugä¿¡æ¯
                    logger.info(f"æ”å½±æ©Ÿç‹€æ…‹: {st.session_state.camera_active}")
                    logger.info(f"æ”å½±æ©Ÿåœ–ç‰‡å­˜åœ¨: {'current_camera_image' in st.session_state}")
                    logger.info(f"æ”å½±æ©Ÿåœ–ç‰‡å…§å®¹: {camera_image is not None}")
                    
                    # ç¢ºå®šæ¨¡å¼åƒæ•¸
                    mode = "virtual_human" if "è™›æ“¬äºº" in response_mode else "chat"
                    
                    # ä½¿ç”¨çµ±ä¸€çš„æ ¸å¿ƒè™•ç†å‡½æ•¸
                    response_text, updated_profile = safe_run_async(process_user_request(
                        message=user_input,
                        image=camera_image,
                        user_profile=st.session_state.user_profile,
                        interaction_mode=interaction_mode,
                        session_id="streamlit_session",
                        response_mode=mode,
                        max_tokens=max_tokens,
                        temperature=temperature
                    ))
                    
                    # æ›´æ–°èŠå¤©æ­·å²
                    st.session_state.chat_history.append((user_input, response_text))
                    
                    # æ›´æ–°ç”¨æˆ¶æª”æ¡ˆ
                    st.session_state.user_profile = updated_profile
                    
                    st.rerun()
                    
                except Exception as e:
                    st.error(f"è™•ç†è¨Šæ¯æ™‚å‡ºéŒ¯: {e}")
                    logger.error(f"Message processing error: {e}")
    
    # æŒ‰éˆ•å€åŸŸ
    col_btn1, col_btn2 = st.columns(2)
    
    with col_btn1:
        if st.button("ğŸ—‘ï¸ æ¸…é™¤å°è©±"):
            st.session_state.chat_history = []
            st.session_state.user_profile = {}
            # é‡æ–°æ·»åŠ æ‰“æ‹›å‘¼è¨Šæ¯
            greeting_message = "æ‚¨å¥½ï¼æˆ‘æ˜¯ AI éŠ·å”®åŠ©ç†ï¼Œå¾ˆé«˜èˆˆç‚ºæ‚¨æœå‹™ã€‚æ‚¨å¯ä»¥è©¢å•ç”¢å“ã€å®‰æ’æœƒè­°ï¼Œæˆ–ä¸Šå‚³åç‰‡è®“æˆ‘æ›´èªè­˜æ‚¨ï¼"
            st.session_state.chat_history.append(("", greeting_message))
            st.rerun()
    
    with col_btn2:
        if st.button("ğŸ“‹ åŒ¯å‡ºå°è©±"):
            if st.session_state.chat_history:
                export_data = {
                    "timestamp": datetime.now().isoformat(),
                    "chat_history": st.session_state.chat_history,
                    "user_profile": st.session_state.user_profile,
                    "emotion_history": st.session_state.emotion_history
                }
                st.download_button(
                    label="ä¸‹è¼‰ JSON",
                    data=json.dumps(export_data, ensure_ascii=False, indent=2),
                    file_name=f"chat_export_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                    mime="application/json"
                )

with col2:
    st.header("ğŸ‘ï¸ è¦–è¦ºåˆ†æ")
    
    # æ”å½±æ©Ÿæ§åˆ¶
    st.subheader("ğŸ“· æ”å½±æ©Ÿæ§åˆ¶")
    
    # æ”å½±æ©Ÿå•Ÿå‹•æŒ‰éˆ•
    if not st.session_state.camera_active:
        if st.button("ğŸ“¹ å•Ÿå‹•æ”å½±æ©Ÿ", type="primary"):
            st.session_state.camera_active = True
            st.success("æ”å½±æ©Ÿå·²å•Ÿå‹•ï¼")
            st.rerun()
    else:
        if st.button("â¹ï¸ åœæ­¢æ”å½±æ©Ÿ", type="secondary"):
            st.session_state.camera_active = False
            st.session_state.current_emotion = None
            st.info("æ”å½±æ©Ÿå·²åœæ­¢")
            st.rerun()
    
    # æ”å½±æ©Ÿç•«é¢
    camera_placeholder = st.empty()
    
    # æƒ…ç·’é¡¯ç¤º
    emotion_placeholder = st.empty()
    
    # åœ–ç‰‡ä¸Šå‚³
    st.subheader("ğŸ“¸ åœ–ç‰‡ä¸Šå‚³")
    uploaded_file = st.file_uploader(
        "ä¸Šå‚³åç‰‡æˆ–åœ–ç‰‡",
        type=['png', 'jpg', 'jpeg'],
        help="æ”¯æ´ PNGã€JPGã€JPEG æ ¼å¼"
    )
    
    if uploaded_file is not None:
        # é¡¯ç¤ºä¸Šå‚³çš„åœ–ç‰‡
        image = Image.open(uploaded_file)
        st.image(image, caption="ä¸Šå‚³çš„åœ–ç‰‡", use_column_width=True)
        
        # è™•ç†åœ–ç‰‡
        if st.button("ğŸ” åˆ†æåœ–ç‰‡"):
            with st.spinner("æ­£åœ¨åˆ†æåœ–ç‰‡..."):
                try:
                    # ç¢ºå®šæ¨¡å¼åƒæ•¸
                    mode = "virtual_human" if "è™›æ“¬äºº" in response_mode else "chat"
                    
                    # ä½¿ç”¨çµ±ä¸€çš„æ ¸å¿ƒè™•ç†å‡½æ•¸
                    response_text, updated_profile = safe_run_async(process_user_request(
                        message="",
                        image=image,  # ç›´æ¥å‚³é PIL Image
                        user_profile=st.session_state.user_profile,
                        interaction_mode=interaction_mode,
                        session_id="streamlit_session",
                        response_mode=mode,
                        max_tokens=max_tokens,
                        temperature=temperature
                    ))
                    
                    # æ›´æ–°èŠå¤©æ­·å²
                    st.session_state.chat_history.append(("(åœ–ç‰‡åˆ†æ)", response_text))
                    
                    # æ›´æ–°ç”¨æˆ¶æª”æ¡ˆ
                    st.session_state.user_profile = updated_profile
                    
                    st.success("åœ–ç‰‡åˆ†æå®Œæˆï¼")
                    st.rerun()
                    
                except Exception as e:
                    st.error(f"åœ–ç‰‡åˆ†æå¤±æ•—: {e}")
                    logger.error(f"Image analysis error: {e}")

# æ”å½±æ©Ÿè™•ç†å‡½æ•¸
def process_camera():
    """è™•ç†æ”å½±æ©Ÿç•«é¢å’Œæƒ…ç·’åˆ†æ"""
    if not st.session_state.camera_active or not vision_enabled:
        return
    
    try:
        # ä½¿ç”¨ Streamlit çš„æ”å½±æ©Ÿè¼¸å…¥
        camera_input = st.camera_input("æ”å½±æ©Ÿç•«é¢", key="camera")
        
        if camera_input is not None:
            # è½‰æ›åœ–ç‰‡æ ¼å¼
            image = Image.open(camera_input)
            
            # å„²å­˜æ”å½±æ©Ÿåœ–ç‰‡ä¾›èŠå¤©ç³»çµ±ä½¿ç”¨
            buffered = io.BytesIO()
            image.save(buffered, format="PNG")
            img_str = base64.b64encode(buffered.getvalue()).decode()
            st.session_state.current_camera_image = img_str
            logger.info(f"æ”å½±æ©Ÿåœ–ç‰‡å·²ä¿å­˜ï¼Œé•·åº¦: {len(img_str)}")
            
            # é€²è¡Œæƒ…ç·’åˆ†æ
            try:
                # ä½¿ç”¨ VisionAgent åˆ†ææƒ…ç·’
                emotion_result = safe_run_async(
                    st.session_state.vision_agent.analyze_emotion(img_str)
                )
                
                logger.info(f"æƒ…ç·’åˆ†æçµæœ: {emotion_result}")
                
                if emotion_result:
                    st.session_state.current_emotion = emotion_result
                    st.session_state.emotion_history.append({
                        "timestamp": datetime.now().isoformat(),
                        "emotion": emotion_result
                    })
                    
                    # é¡¯ç¤ºæƒ…ç·’åˆ†æçµæœ
                    with emotion_placeholder.container():
                        emotion_data = emotion_result
                        st.markdown(f"""
                        <div class="emotion-display">
                            <h3>ç•¶å‰æƒ…ç·’: {emotion_data.get('emotion', 'Unknown')}</h3>
                            <p>ä¿¡å¿ƒåº¦: {emotion_data.get('confidence', 0):.2f}</p>
                            <p>å»ºè­°: {emotion_data.get('suggestion', '')}</p>
                        </div>
                        """, unsafe_allow_html=True)
                else:
                    st.warning("æœªèƒ½åˆ†æå‡ºæƒ…ç·’")
                        
            except Exception as e:
                logger.error(f"Emotion analysis error: {e}")
                st.error(f"æƒ…ç·’åˆ†æå¤±æ•—: {e}")
                
    except Exception as e:
        logger.error(f"Camera processing error: {e}")
        st.error(f"æ”å½±æ©Ÿè™•ç†å¤±æ•—: {e}")

# æ”å½±æ©Ÿè™•ç†
if st.session_state.camera_active and vision_enabled:
    with camera_placeholder:
        process_camera()

# æƒ…ç·’æ­·å²
if st.session_state.emotion_history:
    with st.expander("ğŸ“Š æƒ…ç·’æ­·å²"):
        for record in st.session_state.emotion_history[-10:]:  # é¡¯ç¤ºæœ€è¿‘10ç­†
            st.write(f"**{record['timestamp']}**: {record['emotion'].get('emotion', 'Unknown')} ({record['emotion'].get('confidence', 0):.2f})")

# é è…³
st.markdown("---")
st.markdown("""
<div style="text-align: center; color: #666; margin-top: 2rem;">
    <p>ğŸ¤– AI Sales æ™ºèƒ½éŠ·å”®åŠ©æ‰‹ v2.0 | æ”¯æ´å³æ™‚æƒ…ç·’åˆ†æ</p>
    <p>Built with Streamlit | Â© 2024 C360 Company</p>
</div>
""", unsafe_allow_html=True)
